03장
지도학습(supervised learning)
	정답을 알려주면서 진행되는 학습
	데이터와 레이블(정답)이 함께 제공
	주어진 데이터와 레이블을 이용해 새로운 데이터의 레이블을 예측
	분류, 회귀
비지도학습(unsupervised learning)
	레이블이 없이 진행되는 학습
	데이터 자체에서 패턴을 찾아낼때 사용
	군집화, 차원축소
분류(classfication)
	데이터가 입력되었을 때 지도학습을 통해 미리 학습된 레이블 중 하나 또는 여러 개의 레이블로 예측하는 것
	이진 분류 : 둘 중 하나의 값으로 분류하는 경우
	다중 분류 : 여러 개의 분류값 중에서 하나의 값으로 예측
	다중 레이블 분류 : 데이터가 입력됬을 때 두 개 이상의 레이블로 분류
회귀(regression)
	입력된 데이터에 대해 연속된 값으로 예측
과소적합(underfitting)
	데이터에서 충분히 특징을 찾아내지 못하고 모델을 학습
과대적합(overfitting)
	필요이상의 특징으로 학습할 경우 모델
혼동 행렬(confusion matrix)
	모델의 성능을 평가할 때 사용하는 지표
머신러닝 모델의 성능 평가
	TP(true positive) : 맞는 것을 올바르게 예측한 것
	TN(true negative) : 틀린 것을 올바르게 예측한 것
	FP(false positive) : 틀린 것을 맞다고 잘못 예측한 것
	FN(false negative) : 맞는 것을 틀렸다고 잘못 예측한 것
	정확도 : 모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는지
	정밀도 : 모델의 예측값이 얼마나 정확하게 예측됐는가
	재현율 : 실제값 중에서 모델이 검출한 실제값의 비율을 나타내는 지표
	F1 점수 : 정밀도와 재현율의 조화평균 수치
	k-폴드 교차 검증 : n번의 검증 과정을 통해 n개의 검증 결과를 평균

04장
k-최근접 이웃
	데이터 분류에 사용
	가까운 k개의 데이터를 찾아 k개의 레이블 중 가장 많이 분류된 값으로 데이터 분류
	벡터 공간 속에서 거리를 계산해 가까운 이웃부터 먼 이웃까지 판단
	장점
		이해가 쉽다
		숫자로 구분된 속성에 우수한 성능
		별도의 모델 학습이 필요 없다
	단점
		속도가 느리다
		예측값이 지역 정보에 많이 편향
	kNN의 조절 가능한 변수는 이웃의 개수 k
	k의 개수에 따라 모델의 예측값과 달라진다
	검증 데이터를 사용해 가장 예측율이 높은 k를 찾는 것
서포트 벡터 머신(SVM)
	결정 경계 : 서로 다른 분류값을 결정하는 경계
	서포트 벡터 : 결정 경계를 만드는데 영향을 주는 최전방 데이터 포인트
	마진 : 서포트 벡터와 결정 경계 사이의 거리
의사결정 트리
	데이터 분류 및 회귀에 사용되는 지도학습 알고리즘
나이브 베이즈
	데이터를 나이브(단순)하게 독립적인 사건으로 가정하고, 이 독립 사건들을 베이즈 이론에 대입시켜 가장 높은 확률의 레이블로 분류를 실행하는 알고리즘
앙상블
	여러 개의 분류 모델을 조합해서 더 나은 성능을 내는 방법
군집화
	비지도학습의 일종으로, 데이터의 특징만으로 비슷한 데이터들끼리 모아 군집된 클래스로 분류
선형회귀
	관찰된 데이터들을 기반으로 하나의 함수를 구해서 관찰되지 않은 데이터의 값을 예측하는 것
